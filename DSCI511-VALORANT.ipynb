{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ea9782b3",
   "metadata": {},
   "source": [
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "405ab2a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "#read in list of youtubers from file\n",
    "\n",
    "def get_channels_names(file_path):\n",
    "    youtubers = pd.read_csv(file_path, sep = \",\", header = 0)\n",
    "    return youtubers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c1064cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "youtubers = get_channels_names(\"data/Youtubers.csv\")\n",
    "youtubers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af63f266",
   "metadata": {},
   "outputs": [],
   "source": [
    "from googleapiclient.discovery import build\n",
    "#building youtube service\n",
    "def youtube_build_service(YOUTUBE_API_SERVICE_NAME, \n",
    "                          YOUTUBE_API_VERSION,\n",
    "                          KEY):\n",
    "    return build(YOUTUBE_API_SERVICE_NAME,\n",
    "                 YOUTUBE_API_VERSION,\n",
    "                 developerKey=KEY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "424faabd",
   "metadata": {},
   "outputs": [],
   "source": [
    "YOUTUBE_API_SERVICE_NAME = \"youtube\"\n",
    "YOUTUBE_API_VERSION = \"v3\"\n",
    "api_key_1 = \"AIzaSyCuPRmg3boEYuCK_IUmX5QthRiVnwOGkFk\"\n",
    "api_key_2  = \"AIzaSyCvJwM6a-NpqrXhogr3-ERGVCod6k-rg8Q\"\n",
    "api_key = \"AIzaSyCBCRhyNZh98DEOWx0UH4QFgAMqbcVJqho\"\n",
    "\n",
    "youtube_service = youtube_build_service(YOUTUBE_API_SERVICE_NAME,\n",
    "                                       YOUTUBE_API_VERSION, \n",
    "                                       api_key)\n",
    "youtube_service"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c58e47d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "\n",
    "#Parse channel URL to return channel ID. Return URL.\n",
    "\n",
    "def get_channel_id(channel_url):\n",
    "    url =\"\" \n",
    "    #getting json\n",
    "    resp = requests.get(channel_url)\n",
    "    data = BeautifulSoup(resp.text, \"html.parser\")\n",
    "    #finding \"externalId\" that has the channel id no matter what is link structure\n",
    "    data_s = str(data)\n",
    "    \n",
    "    search_url = re.search('\"externalId\":',data_s)\n",
    "    start, end = search_url.span()\n",
    "    #finding the url after the id, using index\n",
    "    for i in range(end , end+100):\n",
    "        if data_s[i] == \",\":\n",
    "            break\n",
    "        url += data_s[i]\n",
    "    url = url.split('\"')[1]\n",
    "    return url\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e485f02",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get statistics, snippet and contentDetails for Channel from YouTube API\n",
    "##Documentation for returned values: https://developers.google.com/youtube/v3/docs/channels\n",
    "\n",
    "def get_channel_details(youtube, **kwargs):\n",
    "    return youtube.channels().list(\n",
    "        part=\"statistics,snippet,contentDetails\",\n",
    "        **kwargs\n",
    "    ).execute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35c438d9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Get channel details for specified list of youtubers. \n",
    "##Return channel_id, channel_title, channel_subscriber_count, channel_video_count, channel_view_count for each youtuber\n",
    "\n",
    "def get_channels_details_info(youtubers, youtube_service):\n",
    "    dict_youtubers = {}\n",
    "    l_youtubers = []\n",
    "    for index in range(len(youtubers[\"url\"])):\n",
    "        # get the channel ID from the URL\n",
    "        channel_id= get_channel_id(youtubers[\"url\"].iloc[index])\n",
    "        # get the channel details\n",
    "        response = get_channel_details(youtube_service, id=channel_id)\n",
    "        snippet = response[\"items\"][0][\"snippet\"]\n",
    "        statistics = response[\"items\"][0][\"statistics\"]\n",
    "        dict_youtubers = {\n",
    "            \"channel_id\":channel_id,\n",
    "            \"channel_title\" : snippet[\"title\"],\n",
    "            \"channel_subscriber_count\" : statistics[\"subscriberCount\"],\n",
    "            \"channel_video_count\" : statistics[\"videoCount\"],\n",
    "            \"channel_view_count\"  : statistics[\"viewCount\"] \n",
    "        }\n",
    "        l_youtubers.append(dict_youtubers)\n",
    "        \n",
    "    return l_youtubers\n",
    "    \n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1d1fcc9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#get channels info\n",
    "##API CALL: QUOTA COUNT = 9\n",
    "\n",
    "#uncomment this section\n",
    "# channels_info = get_channels_details_info(youtubers, youtube_service)\n",
    "df = pd.DataFrame(channels_info)\n",
    "#save to csv file\n",
    "df.to_csv('data/channels_info.csv')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fb02c4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get video or channel information based on search parameter specified from YouTube API\n",
    "##https://developers.google.com/youtube/v3/docs/search\n",
    "\n",
    "def get_channel_videos(youtube, **kwargs):\n",
    "    return youtube.search().list(\n",
    "        **kwargs\n",
    "    ).execute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a6d8e4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get snippet, contentDetails, statistics for video from YouTube API\n",
    "##snippet property contains the channelId, title, description, tags, and categoryId properties\n",
    "##https://developers.google.com/youtube/v3/docs/videos/list\n",
    "\n",
    "def get_video_details(youtube, **kwargs):\n",
    "    return youtube.videos().list(\n",
    "        part=\"snippet,contentDetails,statistics\",\n",
    "        **kwargs\n",
    "    ).execute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "faaf7977",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Takes video_response from get_video_details as argument. Parses response. \n",
    "# Returns dictionary containing : {\n",
    "#         \"Title\": title,\n",
    "#         \"Channel Title\": channel_title,\n",
    "#         \"Channel ID\": channel_id\n",
    "#         \"Publish time\": publish_time,\n",
    "#         \"Duration\": duration_str,\n",
    "#         \"Number of comments\": comment_count,\n",
    "#         \"Number of likes\": like_count,\n",
    "#         \"Number of views\": view_count\n",
    "#     }\n",
    "\n",
    "\n",
    "def video_infos(video_response):\n",
    "     \n",
    "    items = video_response.get(\"items\")[0]\n",
    "    # get the snippet, statistics & content details from the video response\n",
    "    snippet         = items[\"snippet\"]\n",
    "    statistics      = items[\"statistics\"]\n",
    "    content_details = items[\"contentDetails\"]\n",
    "    # get infos from the snippet\n",
    "    channel_title = snippet[\"channelTitle\"]\n",
    "    title         = snippet[\"title\"]\n",
    "    publish_time  = snippet[\"publishedAt\"]\n",
    "    \n",
    "    # get stats infos\n",
    "    comment_count = statistics[\"commentCount\"]\n",
    "    like_count    = statistics[\"likeCount\"]\n",
    "    view_count    = statistics[\"viewCount\"]\n",
    "    # get duration from content details\n",
    "    duration = content_details[\"duration\"]\n",
    "    \n",
    "    # duration in the form of something like 'PT5H50M15S'\n",
    "    # parsing it to be something like '5:50:15'\n",
    "    parsed_duration = re.search(f\"PT(\\d+H)?(\\d+M)?(\\d+S)?\", duration).groups()\n",
    "    duration_str = \"\"\n",
    "    for d in parsed_duration:\n",
    "        if d:\n",
    "            duration_str += f\"{d[:-1]}:\"\n",
    "    duration_str = duration_str.strip(\":\")\n",
    "    \n",
    "    dict_video_info = {\n",
    "        \"Title\": title,\n",
    "        \"Channel Title\": channel_title,\n",
    "        \"Publish time\": publish_time,\n",
    "        \"Duration\": duration_str,\n",
    "        \"Number of comments\": comment_count,\n",
    "        \"Number of likes\": like_count,\n",
    "        \"Number of views\": view_count\n",
    "    }\n",
    "    \n",
    "    return dict_video_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2df0c1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Returns videos from specified channel. Takes youtube_service, channel_id, video limit (default 5) as arguments\n",
    "##Quota (for running get_channel_videos) = 101 per channel with video limit 5\n",
    "##API CALLS: get_channel_videos, get_video_details\n",
    "\n",
    "def get_videos_from_channel(youtube_service, channel_id, videos_limit = 5):\n",
    "\n",
    "    # counting number of videos grabbed\n",
    "    n_videos = 0\n",
    "    next_page_token = None\n",
    "    list_videos = []\n",
    "\n",
    "    while n_videos < videos_limit:\n",
    "        #paramters to select the videos\n",
    "        #only valorant related videos\n",
    "        params = {\n",
    "            'part': 'snippet',\n",
    "            'q': 'valorant',\n",
    "            'channelId': channel_id,\n",
    "            'type': 'video',\n",
    "        }\n",
    "        \n",
    "        if next_page_token:\n",
    "            params['pageToken'] = next_page_token\n",
    "        \n",
    "        #getting channel videos based on parameters\n",
    "        res = get_channel_videos(youtube_service, **params)\n",
    "        #getting items\n",
    "        channel_videos = res.get(\"items\")\n",
    "    \n",
    "        for video in channel_videos:\n",
    "            if n_videos == videos_limit:\n",
    "                break\n",
    "                \n",
    "            n_videos += 1\n",
    "            video_id = video[\"id\"][\"videoId\"]\n",
    "            # easily construct video URL by its ID\n",
    "            video_url = f\"https://www.youtube.com/watch?v={video_id}\"\n",
    "            \n",
    "            video_response = get_video_details(youtube_service, id=video_id)\n",
    "            \n",
    "            print(f\"================Video #{n_videos}================\")\n",
    "            # get video details in dictionary\n",
    "            dictionary_video = video_infos(video_response)\n",
    "            dictionary_video[\"video_id\"] = video_id\n",
    "            dictionary_video[\"url\"] = video_url \n",
    "            \n",
    "            \n",
    "            list_videos.append(dictionary_video)\n",
    "            \n",
    "            print(video_infos(video_response))\n",
    "            print(f\"Video URL: {video_url}\")\n",
    "            print(\"=\"*40)\n",
    "        print(\"*\"*100)\n",
    "        # if there is a next page, then add it to our parameters\n",
    "        # to proceed to the next page\n",
    "        if \"nextPageToken\" in res:\n",
    "            next_page_token = res[\"nextPageToken\"]\n",
    "    return list_videos\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c02b786",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Loop through channel info data frame and retrieve videos for all listed channels\n",
    "\n",
    "videos_retrieved = []\n",
    "\n",
    "for channel_id in df[\"channel_id\"]:\n",
    "    videos_retrieved.extend(get_videos_from_channel(youtube_service, channel_id,1))\n",
    "\n",
    "videos_retrieved"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe84e609",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_videos = pd.DataFrame(videos_retrieved)\n",
    "#save to csv file\n",
    "# df_videos.to_csv('data/videos_info.csv')\n",
    "df_videos\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5ab9f64",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get snippet for commentThread, flexible definition of arguments\n",
    "##Response documentation https://developers.google.com/youtube/v3/docs/commentThreads/list\n",
    "\n",
    "def get_comments(youtube, **kwargs):\n",
    "    return youtube.commentThreads().list(\n",
    "        part=\"snippet\",\n",
    "        **kwargs\n",
    "    ).execute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12bf39c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# #Returns a list of comment info :comments_dict = {\n",
    "#                 \"Comment ID\":comment_id, \n",
    "#                 \"Comment\": comment,\n",
    "#                 \"Likes\": like_count,\n",
    "#                 \"Replies\": reply_count\n",
    "#                 \"Channel ID\": channel_id\n",
    "#                 \"Video ID\": videoId\n",
    "#                 }\n",
    "#Arguments: video_id, total_comments (default 100), max_comment_per_page (default 100), order (default by time))\n",
    "\n",
    "##QUOTA USAGE FOR 1 URL: 6\n",
    "\n",
    "def get_comments_video(videoId, total_comments = 100, max_comment_per_page = 100 , order = \"time\"):\n",
    "    #count comments retrieved\n",
    "    comments_nb = 0 \n",
    "\n",
    "    #list to store comment dictionary\n",
    "    list_comments = []\n",
    "    #comment dictionary for storing comment data\n",
    "    comments_dict = {}\n",
    "    \n",
    "    #while comment count less than total comment value get comments\n",
    "    while comments_nb <total_comments:\n",
    "       \n",
    "        params = {\n",
    "                'videoId': videoId, \n",
    "                'maxResults': max_comment_per_page,\n",
    "                'order': 'relevance', # default is 'time' (newest)\n",
    "            }\n",
    "\n",
    "        response = get_comments(youtube_service, **params)\n",
    "\n",
    "        items = response.get(\"items\")\n",
    "\n",
    "\n",
    "        # if items is empty, breakout of the loop\n",
    "        if not items:\n",
    "            break\n",
    "        \n",
    "        for item in items:\n",
    "            #if comments_nb exceeds total_comments, break\n",
    "            if comments_nb >= total_comments:\n",
    "                break \n",
    "            #collect comment text, comment id, reply count, like count, channel id\n",
    "            comment = item['snippet']['topLevelComment']['snippet']['textDisplay']\n",
    "            comment_id = item['snippet']['topLevelComment']['id']\n",
    "            reply_count = item['snippet']['totalReplyCount']\n",
    "            like_count = item['snippet']['topLevelComment']['snippet']['likeCount']\n",
    "\n",
    "            #create dictionary with collected data and video idea\n",
    "            comments_dict = {\n",
    "                \"Comment ID\":comment_id, \n",
    "                \"Comment\": comment,\n",
    "                \"Likes\": like_count,\n",
    "                \"Replies\": reply_count,\n",
    "                \"Video ID\": videoId\n",
    "                }\n",
    "            #increase comments_nb\n",
    "            comments_nb+=1\n",
    "            #add list_comments to comments_dict\n",
    "            list_comments.append(comments_dict)\n",
    "\n",
    "        #if nextPageToken exists, check next page    \n",
    "        if \"nextPageToken\" in response:\n",
    "            # if there is a next page\n",
    "            # add next page token to the params we pass to the function\n",
    "            params[\"pageToken\"] =  response[\"nextPageToken\"]\n",
    "        else:\n",
    "            # must be end of comments!!!!\n",
    "            break\n",
    "   \n",
    "    return list_comments\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a0c4ae2-fb38-47ef-a60e-2f1e170d918a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#save dataframe to .csv file\n",
    "def save_file(file_name, file_content):\n",
    "    df_save = pd.DataFrame(file_content)\n",
    "    df_save.to_csv(\"data/\"+file_name+\".csv\")\n",
    "    return df_save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "923dbe60-30a4-44f1-8a1b-06de68a7c567",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create list of comments\n",
    "\n",
    "comments = []\n",
    "\n",
    "for video_id in df_videos[\"video_id\"]:\n",
    "    comments.extend(get_comments_video(video_id))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4fc2e04-5d89-48c1-a406-9fff313bc69d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#save comments to csv file using save_file\n",
    "df_comments = save_file(\"comments\", comments)\n",
    "df_comments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "222f1fab-5288-4465-9a04-709435f3bb9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#join comment, video and channal data on video and channel id\n",
    "df_video_comment_data = pd.merge(df_videos, df_comments, how = 'outer', left_on = ['video_id'], right_on = ['Video ID'])\n",
    "df_video_comment_channel_data = pd.merge(df_video_comment_data, df_channel_info, how = 'outer', left_on = ['Channel ID'], right_on = ['channel_id'])\n",
    "\n",
    "df_video_comment_channel_data\n",
    "df_video_comment_channel_data.to_csv('data/comments_videos_channel_info.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
