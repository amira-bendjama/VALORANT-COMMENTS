{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b17e1b7-d10b-49c4-a54c-d5f9afa4bb0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "##TO DO##\n",
    "\n",
    "#Reference for what to remove: https://towardsdatascience.com/cleaning-preprocessing-text-data-for-sentiment-analysis-382a41f150d6\n",
    "\n",
    "#load comments file\n",
    "##From comments file get list of unique IDs to group text by for analysis (Channel or Video)\n",
    "\n",
    "#Process selected Text\n",
    "##Requirements for NLP Processing\n",
    "###remove emojis\n",
    "###strip URLs\n",
    "###handle contractions\n",
    "###strip extra characters\n",
    "\n",
    "#Return processed data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "fe47c46f-51dd-4bce-967a-a00eddfadc29",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import pandas as pd\n",
    "#load unique ids from csv file based on either channel or video id\n",
    "def get_id_list(file_path, id_type = 'channel'):\n",
    "    \n",
    "    data = pd.read_csv(file_path, sep = \",\", header = 0)\n",
    "    \n",
    "    #set id_name based on id_type\n",
    "    id_name = ''\n",
    "    if id_type == 'channel':\n",
    "        id_name = 'Channel ID'\n",
    "    if id_type == 'video':\n",
    "        id_name = 'Video ID'\n",
    "        \n",
    "    #collect unique video IDs from file\n",
    "    id_list = []\n",
    "    \n",
    "    for unique_id in data[id_name]:\n",
    "        if unique_id not in id_list:\n",
    "            id_list.append(unique_id)\n",
    "            \n",
    "    return id_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "e2a96f59-37a1-4543-a0e6-91bfa23324ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "channel_ids = get_id_list('data/comments.csv', 'video')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "409f6903-a52d-40a3-b918-5257c1703427",
   "metadata": {},
   "outputs": [],
   "source": [
    "#load comments from file, grouped by unique id\n",
    "\n",
    "def get_comments_by_id(file_path, id_list, id_type = 'channel'):\n",
    "    \n",
    "    comments_by_id = {}\n",
    "    data = pd.read_csv(file_path, sep = \",\", header = 0) \n",
    "    \n",
    "    #set id_name based on id_type\n",
    "    id_name = ''\n",
    "    if id_type == 'channel':\n",
    "        id_name = 'Channel ID'\n",
    "    if id_type == 'video':\n",
    "        id_name = 'Video ID'\n",
    "        \n",
    "    for unique_id in id_list:\n",
    "        comments = []\n",
    "        for index, row in data.iterrows():\n",
    "            if row[id_name] == unique_id:\n",
    "                comments.append(row['Comment'])\n",
    "        comments_by_id[unique_id] = comments\n",
    "    \n",
    "    return comments_by_id\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "5d975ed6-f9ad-48be-8f5f-c81fa32df534",
   "metadata": {},
   "outputs": [],
   "source": [
    "comments_by_video = get_comments_by_id('data/comments.csv', channel_ids, 'video')\n",
    "\n",
    "#print(comments_by_video['Kl2XzD5DMoY'])\n",
    "\n",
    "sykkuno_comments = comments_by_video['Kl2XzD5DMoY']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "d7a9b72c-545f-4196-b516-0ed2be509381",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Remove URLs\n",
    "# https://medium.com/r/?url=https%3A%2F%2Fstackoverflow.com%2Fa%2F40823105\n",
    "# r'S' matches anything until next whitespace\n",
    "\n",
    "import re\n",
    "\n",
    "def remove_urls(text):\n",
    "    return re.sub(r'https?://\\S+', '', text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "3f29678e-6ab1-4311-b5bf-633d94cf6ded",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting demoji\n",
      "  Downloading demoji-1.1.0-py3-none-any.whl (42 kB)\n",
      "\u001b[K     |████████████████████████████████| 42 kB 2.9 MB/s eta 0:00:011\n",
      "\u001b[?25hInstalling collected packages: demoji\n",
      "Successfully installed demoji-1.1.0\n"
     ]
    }
   ],
   "source": [
    "#Install demoji for identifying emojis\n",
    "#!pip install demoji"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "4f7d454f-ea04-4a1b-bd2b-0b3b111390a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Remove Emojis\n",
    "\n",
    "import demoji\n",
    "\n",
    "#Download codes (only once): demoji.download_codes()\n",
    "##https://pypi.org/project/demoji/\n",
    "\n",
    "#loop through video ids and clean URLs from each file\n",
    "def remove_emojis(text):\n",
    "    return demoji.replace(text, \"\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "6b3e15cc-be8d-4b2b-99f3-7a1eaa1df946",
   "metadata": {},
   "outputs": [],
   "source": [
    "#make all text lowercase\n",
    "\n",
    "def text_lower(text):\n",
    "    new_text = [x.lower() for x in text.split()]\n",
    "    return ' '.join(new_text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "6da330bb-38aa-4f0b-a69e-4e4c89ef0abb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting contractions\n",
      "  Downloading contractions-0.1.73-py2.py3-none-any.whl (8.7 kB)\n",
      "Collecting textsearch>=0.0.21\n",
      "  Downloading textsearch-0.0.24-py2.py3-none-any.whl (7.6 kB)\n",
      "Collecting anyascii\n",
      "  Downloading anyascii-0.3.1-py3-none-any.whl (287 kB)\n",
      "\u001b[K     |████████████████████████████████| 287 kB 6.7 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting pyahocorasick\n",
      "  Downloading pyahocorasick-1.4.4-cp39-cp39-macosx_10_9_x86_64.whl (32 kB)\n",
      "Installing collected packages: pyahocorasick, anyascii, textsearch, contractions\n",
      "Successfully installed anyascii-0.3.1 contractions-0.1.73 pyahocorasick-1.4.4 textsearch-0.0.24\n"
     ]
    }
   ],
   "source": [
    "#install contractions\n",
    "!pip install contractions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "aa1424ee-a734-464c-b542-d4585b313152",
   "metadata": {},
   "outputs": [],
   "source": [
    "#handle contractions (i.e. #39)\n",
    "#Reference https://www.geeksforgeeks.org/nlp-expand-contractions-in-text-processing/\n",
    "#YouTube comment data shows contractions as &#39;\n",
    "# import contractions\n",
    "import contractions\n",
    "\n",
    "def fix_contractions(text):\n",
    " \n",
    "    # create an empty list for expanded words\n",
    "    expanded_words = [] \n",
    "    \n",
    "    for word in text.split():\n",
    "        #sub contraction characters with apostrophe\n",
    "        clean_word = re.sub('&#39;', \"'\", word)\n",
    "        \n",
    "        # using contractions.fix to expand the shortened words\n",
    "        expanded_words.append(contractions.fix(clean_word))  \n",
    "\n",
    "    expanded_text = ' '.join(expanded_words)\n",
    "    return expanded_text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "090a393e-d183-4c45-a7ab-79d240c1ee7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#remove special characters\n",
    "import re\n",
    "\n",
    "def remove_special_char(text):\n",
    "    new_text = re.sub('[^A-Za-z0-9 ]+', '', text)\n",
    "    return new_text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "ab7e43aa-b285-4404-be9c-940bc26c7a78",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Clean text of emojis and URLs\n",
    "\n",
    "def clean_URLs_and_emojis(comment_list):\n",
    "    \n",
    "    clean_comments = []\n",
    "    for comment in comment_list:\n",
    "        text = text_lower(remove_special_char(fix_contractions(remove_emojis(remove_urls(comment)))))\n",
    "        clean_comments.append(text)\n",
    "                            \n",
    "    return clean_comments\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "e0789092-7dbb-4dfa-bb79-7b7d8dd17bb3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['their synergy was so good and all of them played so well', 'when you are the lowest team but you are a main character in an anime but they lost the finals and hey main characters do not always win maybe someday you guys will be legends', 'i can relate to this vidbrmy team we are winning brme i knowi am scared too', 'team scarra had like the highest average in player skill if you ask me they were pretty stacked the fact that team lily that was kind of looking like the weakest on paper going into it ended up going to the finals and getting that close shows how good their teamwork was they all understood their role in the team as players and in terms of who they were playing team lily was by far the best team to watch this tournament because they kept defying expectations brwould be cool to see the tournament happen again with the same teams even though it would never happen', 'sykkuno be like quotwe are the lowest ranked team in valorant buti knifed toast guysi knifed toast hahahahahaquot a href', 'but you have the best chem ever i loved watching this team play throughout the whole otv tournament yvonne and lily low key popping off', 'the ending was so sad but the fact that they got to the finals is amazing', 'i had very low expectations from team lily this tourney but they popped off', 'their teamwork was surprisingly great', 'a href yeah sykunno fight againbrsykunno bdiesb', 'they gave a strong comeback to opponent everytime that is why he is the coolest', 'this happened last tourney too toasts team was technically the weakest on paper and they used the same team comp the whole time no duelist too but their comms were phenomenal team lilys synergy beats all no matter the rank', 'sean and danny were the pillars of the team but sykkuno lily and yvonne really held their own', 'i have watched every upload of this game from the otv channel to lilys yvonnes and now sykkuno and it is still so entertaining and exciting every time for me they are the real winners because it was so unexpected for them to go into the finals and yet they did and it was not an easy fight they did not just let scarras team win considering their team is stacked they did their best and it was amazing to see their group synergy and great comms hope to see them play again together also good job editor this again is well edited thanks for the different povs really entertaining', 'team lily is literally the power of friendship teamwork same thing', 'the quotwhat if we could be winners for oncequot hit too close to home you guys did great', 'you made it to the finals i am really proud how much you guys improved since the last tournament i will have to say chamber is your agent i hope someday i can play almost as good as you because i really suck at this game but i love it', 'the games against scarra and jojo my anxiety levels were going up and down with all the intense overtimes', 'i miss team lily they were such a good group', 'imma just put it out there you and your friends are super awesome', 'the teamwork was clearly awesome the comms were on point and all were so positive i need more content from this squad', 'sometimes winning is about upstaging expectations and by that standard i would consider them the tournament champions while there may not be a participation trophy it was still an incredibly close last game', 'i love how syk is so humble and wholesome but he is really good at the games he plays lt3', 'the drunk danny jett for the thumbnail art is so cute congrats on doing so well in the tourney team lily', 'i watched the whole thing live and i am just going to say sykkuno you are cracked good job on the tournament', 'jodi is really good but the a href caught me off guard she would almost gotten yvonne but sykkuno was at market jodi did not know and manage to help yvonne that was a good game', 'i had the best time watching your teams games ahhhhh congrats to team lily', '100 echoing this sykkuno has the duality of an iron and a radiant xd', 'love that sykkuno got the winning shot on that 32 round game', 'danny amp sean really crack sykkuno lily amp yvonne surprisingly crack teams synergy bring them to runnerup really enjoyed the whole tournament', 'i enjoyed this tournament so much team lily did so good', 'that ending was so sad but so inspirational at the same time', 'love it lt3 teamwork was really impressive bab you did great in the tournament gg', 'can we take a moment to appreciate the editing it is just so good', 'even at the finals they were neck and neck with the scores amazing', 'watching sykkuno play valo is always a joy whether hes winning or losing', 'so much planning an energetic team they did so well and worked together using communication', 'i loved watching team lily they all played so well as a team', 'and the fact that they wanted to play one last time and end with a win which they eventually did that is how much team lily was the standout team of this tourney even though it was for charity', 'the fact you guys won over jody and john is so amazing', 'your team actually did great sykkuno the teamwork was amazing', 'spectacular team and performance from skill to entertainment', 'the overtime round was the highlight point lol back and forth quota decade off my lifequot', 'the fact that they made it to the finals even if they are the lowest rank player the teamwork', 'honestly if the lowest ranked team makes it to the finals someone needs to remake the ranking process xd', 'sykkunos plot armor is activated and buff his team', 'as the lowest ranked team they are one of the teams that have a great unexpected chemistry', 'team lily did so well i am going to need them to play more games together', 'this editor is really good making some funny and cool clips', 'last time lilys team won in lol now she is winning in valorant', 'the synergy i play valorant with my friends and none of us can cordinate as well as team lily did', 'lilys team was the best underrated team', 'this team was so good ahh', 'i love syks editors so muchthey are the reason i can never get tired of watching sykkuno', 'i have seen it live but sykkunos sadge farming at the end got me in my feels again', 'yeah team scarra was just way to good but this team was the team that i thought would really win', 'you did great team lily', 'everytime i watch this i keep laughing at the first fight with the knives and the slow music and slomo video editing it is too funny and dramatic xd especially with toasts team moving side ways in syncbr', 'this was beautifully edited', 'so good enjoyed every min', 'i love the editing so much been cracking up the whole time', 'hope you have more tournament like thisbrrewatching for the 3rd time ksks', 'team lily hustled this tournament so well xd', 'do not feel down about a silly tournament you guys kicked ass', 'i love them team lily was amazing', 'lmaooo i love the 5head edit on sykkuno its so funny ahh chemberkkuno is just so damn cool we need more chamberkkuno', 'this was like watching a sports anime but props to you all everyone really popped off', 'you could make an anime out of this entire tournament alone the storyline and characters you all see where i am going with this', 'good stuff you are all aces in my book', 'you all did your best', 'one of the most satisfied highlight video i have ever seen in my life', 'you did great cheers team lily', 'sykunno your so wholesome i hate it but yet love it at the same time', 'i honestly to god thought they were going to lose every game all the other teams had better players i will have to say yvonne has improved so much', 'at a href you shall not passbrbrbdanny knifed them allbbrbrboxbox they are totally did pass brbrlmao so cute', 'i love this editing chefkissbr136 the struggles pretty good insert there not going to lie', 'half of our team went drinking', 'no way they beat toasts team', 'sykkunos editor with the audio sfx is going crazy amazing', 'such a good teamwork', 'you guys did soo amazing brsecond place right', 'you are doing very good but sometimes luck is not on your side and you cannot always win brto be honest i am bad at the game too but sometimes when i in good condition i will do really good just like you', 'why did it feel like every sick kill sykkuno had against scarras team was on peter', 'this would be so much fun versing your own friends imagine having 9 friends to do this with could not be me sadly', 'thanks for the edit editing team you made an amazing game more awesome with the edits hahaha', 'i was so emotionally invested in this round', 'sykkunos massive knifing skills payed off pogbrvery impressive result though', 'sykkuno pressed ultbrchamber you are so deadbrsykkuno i am so dead i am so dead', 'you are team works well together', 'to be honest even thought sykkuno is not the best player his tap firing is super clean', 'sykkuno was definitely the main character of this tournament', 'dude they did pretty good', 'holy shit you almost had that that is why underdogs are my favorite ggs team lily', 'a href i have been noticing how sweet poki and sykk are to each other', 'sean was a lurking god this tournament', 'happy holidays love watching your videos miss valorent game play', 'you are so good at valorant sykkuno', 'low rank does not meant your bad', 'sykkuno so good at pretending to be weak', 'so right before the tournamentbri said to myselfbrif the team rae is on goes undefeated i will download valorant and start playing and what do you know']\n"
     ]
    }
   ],
   "source": [
    "#Clean selected comments of URLs and emojis\n",
    "\n",
    "clean_sykkuno_comments = clean_URLs_and_emojis(sykkuno_comments)\n",
    "\n",
    "print(clean_sykkuno_comments)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7787ece-ca33-4d10-8da4-af25ec535cd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#tokenize text\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
